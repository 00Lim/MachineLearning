## Machine Learning System Design

#### <u>Prioritizing what to work on - spam classification example</u>

우리가 스팸 메일로 분류할 특징

- 스팸 (1)
  - 잘못된 철자
- 스팸 아님 (0)
  - 실제 내용

<br>

<b>One approach - choosing your own features</b>

스팸 메일인지 아닌지 구별할 수 있는 100개의 단어를 선택했다.

- 스팸 메일 - buy, discount, deal, ...
- 정상 메일 - Andrew, now, ...

이것들을 하나의 긴 벡터에 넣는다. -> 참조벡터로 인코딩한다.

vector x는 그 단어가 메일에서 나타나면 1, 나타나지 않으면 0으로 표현한다.

단어가 여러번 나타나도 1이다.

실제로는 training set에서 가장 자주 나타나는 10,000개에서 50,000개의 단어를 선택한다.

<br>

<b>What's the best use of your time to improve system accuracy?</b>

- 많은 데이터를 수집한다.

- 이메일 라우팅 정보에 기반한 알고리즘을 개선한다.
- 이메일 본문에 기반한 알고리즘을 개선헌다.
- 의도적으로 철자를 틀리게 쓴 단어를 검출하는 알고리즘을 개선한다.

<br>

<b>Error analysis</b>

처음에는 빠르게 구현할 수 있는 간단한 알고리즘을 구축하여 시작하는것이 좋다.

- Cross validation data로 테스트 한다.
- Learning curve를 그려서 데이터를 늘리거나, feature를 늘리는 방법이 도움이 될 지 결정한다.
- 에러를 일으키는 데이터를 분석하여 어떤 종류의 데이터가 오류를 일으키는지 관찰한다.

<br>

오류를 일으키는 메일을 수동으로 분류한다.

1. 어떤 종류의 메일이 오류를 일으키는지
2. 알고리즘이 똑바로 분류하는데 도움이 될만한 feature가 무엇인지

위의 방식으로 분류한 뒤 알고리즘의 성능을 높일 수 있는 방법을 찾는다.

<br>

비슷한 단어를 같은 단어처럼 취급을 해야할까?

- 형태소 분석기가 도움이 될 것이다.
- 이것이 알고리즘을 더 좋게 만들수도 있지만 더 나쁘게 만들수도 있다.

수치를 분석하고 변경하는것이 알고리즘을 얼마나 더 좋게 만들 수 있는지 확인한다.

에러를 분석하고 알고리즘을 발전시킬때에는 test set이 아니라 cross validation에서 수행을 해야 한다.

<br>

<br>

#### <u>Error Metrics for skewed analysis</u>

분류할 데이터가 그렇지 않은 데이터보다 훨씬 작을 때 이 데이터를 skewed classes라고 한다.

skewed class를 분류할때는 일반적인 방법이 아니라 다른 방법으로 에러를 확인한다.

<br>

<b>Precision and recall</b>

precision과 recall이라는 두개의 새로운 지표가 있다.

이 두개의 값은 0과 1 사이의 값을 가진다.

분류

- True positive (we guess 1, it was 1)
- False positive (we guess 1, it was 0)
- True negative (we guess 0, it was 0)
- False negative (we guess 0. it was 1)

<br>

- Precision

  - 알고리즘이 얼마나 자주 틀리는지

  - 1로 결정한 값 중 얼마만큼이 진짜 1인지
    $$
    \frac{\mbox{True positive}}{\mbox{True positive + False positive}}
    $$

  - 1에 가까울수록 좋다.

- Recall

  - 알고리즘이 얼마나 민감한지

  - 실제 1인 값 중 얼만큼 찾아냈는지
    $$
    \frac{\mbox{True positive}}{\mbox{True positive + False negative}}
    $$
    

  - 1에 가까울수록 좋다.

<br>

<br>

#### <u>Trading off precision and recall</u>

이전에 배운 logistic regression에서는 1인지 아닌지를 판단하는 threshold 기준이 0.5였다.

이 값을 0.7아니 0.8처럼 키우게 되면 암 환자에 대한 정확도는 올라가지만 암환자를 정상인으로 오판하는 정도가 커지게 된다.

즉, high precision, lower recall로 나타난다.

반대로 threshold의 값을 작게 잡으면 high recall, lower precision, 암환자를 오판하는 경우는 작아지지만 정상인도 암환자로 판단하는 경우도 커져서 정확도가 떨어지게 된다.

그렇다면 최적의 threshold의 값은 어떻게 정하면 좋을까.

![threshold](http://www.holehouse.org/mlclass/11_Machine_Learning_System_Design_files/Image%20[2].png)

![](https://wikidocs.net/images/page/4662/des404.PNG)

최적의 알고리즘을 고르려면 성능을 평가하는 두 개의 숫자를 하나로 만드는 것이 더 편하다.

하지만 이 두 숫자들의 평균을 내는 방법은 사용하지 않는다.

대신 F-score를 일반적으로 사용한다.
$$
F_1 \mbox{ score} = 2\frac{PR}{P+R}
$$
만약 P = 0 또는 R = 0이면 F-score는 0이 되고, 완벽한 알고리즘의 경우에는 P = 1, R = 1이 되어 F-score는 1이 된다.

<br>

<br>

#### <u>Data for machine learning</u>

<b>Designing a high accuracy learning system</b>

![](http://www.holehouse.org/mlclass/11_Machine_Learning_System_Design_files/Image%20[4].png)

알고리즘은 대체로 비슷하기 때문에 데이터의 수가 더 많은 것이 적절한 결과를 가져온다.

많은 데이터도 좋기는 좋은 정보들을 많이 가지고 있는 것이 결과를 예측하는데 있어서 더 좋다.

이렇게 많은 데이터를 사용해서 알고리즘을 구성할 때 많은 feature를 처리하는 알고리즘을 사용한다면 이들은 low bias 알고리즘이 될 것이다.

- 작은 training set을 사용한다면
  - J<sub>train</sub>은 작아야 한다.
- 큰 training set을 사용한다면
  - J<sub>train</sub>과 J<sub>test</sub>가 비슷하다면
  - 우리의 복잡한 알고리즘에 over fit하지 않다.
  - 따라서 test set의 에러도 작아야 한다.

또 다른 생각은 알고리즘이 low bias와 low variance를 갖기를 원한다.

- Low bias -> 더 복잡한 알고리즘을 사용
- low variance -> 더 큰 training set을 사용













































