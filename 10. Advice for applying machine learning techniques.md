## Advice for applying Machine Learning

#### <u>Deciding what to try next</u>

<b>Debugging a learning algorithm</b>

예측 성능을 향상시키거나 큰 문제가 발생하면

- training data를 늘린다.
- 더 작은 feature로 시도해본다.
- 추가적인 feature를 얻는다.
- 다항식의 feature를 추가한다.
- 새로운, 더 나은 feature를 만든다.
- 람다를 줄이거나 늘린다....

이런 방식들 중 골라서 사용할 것이다. 하지만 이것이 항상 원하는 결과를 가져오지는 않는다.

<br>

#### <u>Evaluation a hypothesis</u>

일반적인 방법으로는 데이터를 training set 70 : test set 30으로 나눠서 사용한다.

logistic regression에서는 오류를 다음과 같이 정의한다.
$$
err(h_{\theta}(x), y) = \begin{cases}
1, & \mbox{if } h_{\theta} \ge 0.5, y = 0
\mbox{ or if h}_{\theta}(x) < 0.5, y = 1
\\
0 & \mbox{otherwise}
\end{cases}
$$
<br>

<br>

#### <u>Model selection and training validation test sets</u>

모델을 선택하는 방법

![models](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning_files/Image%20[6].png)

1차부터 10차 다항식 중에서 데이터에 맞는 모델을 선택해야 한다.

각각의 함수에 대해 cost function J를 계산하고 오류가 가장 작은 모델을 선택한다.

하지만 이런식으로 선택하게 되면 해당 test set에 대해 overfitting이 생길 수 있기 때문에 살짝 다른 방법을 적용한다.

<br>

우리는 그 전에 data set을 training set 0 : test set30으로 나눠서 사용했다.

이제 이것을 training set 60 : cross validation 20: test set 20으로 나눠서 사용한다.

이전과 같이 각 모델에서 cost function J의 값이 최소화되고 cross validation에서의 cost function의 값도 작은 모델을 고른다.

이렇게 모델의 over fitting 문제를 해결할 수 있다.

<br>

<br>

#### <u>Diagnosis - bias vs. variance</u>

일반적으로 다음의 문제중 하나 때문에 나쁜 결과를 얻을 수 있다.

- High bias - under fitting 문제

- High variance - over fitting 문제

under fitting에서 over fitting으로 이동할수록 모델의 차수가 증가한다.

다항식의 차수가 증가함에 따라 cross validation error와 training error의 그래프는 다음과 같다.

![degree of polynomial d](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning_files/Image%20[10].png)

차수가 너무 작으면 high bias problem이 생긴다.

- cross validation 오류와 training의 오류가 모두 크다는 것을 알 수 있다.
  - Hypothesis function이 훈련 데이터에 적합하지 않다.
  - 둘 중 어느것도 일반화 하지 않는다.

차수가 너무 크면 high variance problem이 생긴다.

- cross validation 오류는 크지만 training의 오류는 크지 않다.
  - over fitting이다.
  - Hypothesis function은 잘 맞지만 일반화를 잘 해야 한다.

<br>

<br>

#### <u>Regularization and bias/variance</u>

우리는 정규화를 할 때 세 가지 사항을 고려해야 한다.

- λ가 클 때
  - 모든 θ의 값이 0에 가까워진다.
  - 따라서 hypothesis function 또한 0에 가까워진다.
  - hihg bias -> under fitting 문제가 생긴다.
- λ가 적당할 때
  - 좋다.
- λ가 작을 때
  - 정규화 항이 0이 된다.
  - high variance -> over fitting 문제가 생긴다.

<br>

<b>Choosing λ</b>

2배씩 증가한다.

- model(1) = λ = 0

- model(2) = λ = 0.01

- model(3) = λ = 0.02

- model(4) = λ = 0.04

  ...

- model(12) = λ = 10

이렇게 모델마다 λ의 값이 다를 때

1. 모델들 중 cost function의 값이 가장 작은 모델을 가져와서
2. cross validation set의 cost function의 값도 충분히 작은지 확인하고
3. test set에서 검사한다.

<br>

<b>Bias/variance as a function of λ</b>

- J<sub>train</sub>
  - λ의 값이 너무 작으면 작은 값이 나온다.(정규화는 0으로 간다.)
  - λ의 값이 너무 크면 high bias에 일치한다.
- J<sub>cv</sub>
  - λ의 값이 너무 작으면 over fitting의 위험이 존재.
  - λ의 값이 너무 크면 under fitting의 위험이 존재

<br>

<br>

#### <u>Learning curves</u>

learning curves는 성능을 향상시키거나 알고리즘이 정상인지 확인하기 위해 종종 사용된다.

- J<sub>train</sub>
  - 작은 사이즈의 training set이 오류가 더 적다.
  - m이 커질수록 오류도 커진다.
- J<sub>cv</sub>
  - 크기가 작을수록 일반화가 덜 되어서 오류가 더 많다.
  - 크기가 커질수록 hypothesis function이 일반화가 더 잘된다.
  - m이 커질수록 오류도 작아진다.

![Learning Curves](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning_files/Image%20[14].png)

<br>

<b>High bias</b>

![High Bias LC](https://deep-diver.github.io/Machine-Learning-Yearning-Korean-Translation/img/30_2.PNG)

- J<sub>train</sub>
  - 처음에는 error가 작지만 점점 늘어난다.
  - 오류가 점점 cross validation에 가까워진다.
- J<sub>cv</sub>
  - 함수가 데이터에 적합하지 않기 때문에 많은 데이터가 있더라도 일반화가 잘 되지 않는다.
  - 따라서 데이터의 증가는 적합하지 않다.
- High bias는 training set과 cross validation의 오류가 둘 다 높기 때문에 발생한다.
- 또 알고리즘이 이미 편향되어 있으므로 데이터가 많아지더라도 도움이 되지 않는다.

<br>

<b>High variance</b>

![High Variance LC](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning_files/Image%20[15].png)

- J<sub>train</sub>
  - 데이터의 수가 작으면 error도 작다.
  - error는 거의 선형 함수처럼 천천히 증가한다.
  - 하지만 그래도 오류는 여전히 작다.
- J<sub>cv</sub>
  - 오류가 크다.
  - High validation문제는 모델이 일반화 되지 않았기 때문에 발생한다.
  - 따라서 데이터의 증가가 도움이 된다.