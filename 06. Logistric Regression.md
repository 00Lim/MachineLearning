## Logistic Regression

#### <u>Classification</u>

예측한 결과 값이 이산적인 값을 가진다.

Linear regression을 사용하여 classification으로 분류를 할 때는 잘 안되는 경우가 많다.

우리가 원하는 값은 0 또는 1이지만 linear regression을 사용하면 그것보다 더 다양한 결과가 나온다.

<br>

#### <u>Hypothesis representation</u>

hθ(x)  = 1 / (1 + e <sup>-θ<sup>T</sup>x</sup>)

(수식...)

##### Interpreting hypothesis output

h<sub>θ</sub>(x) = P(y = 1 | x; θ)

주어진 feature가 x라는 값을 가질때 x가 class 1에 들어갈 확률

0에 들어갈 확률과 1에 들어갈 확률을 더하면 1이 되어야 한다.

<br>

#### <u>Non-linear decision boundaries</u>

더 높은 다항식의 항을 사용하여 더 복잡한 경계를 얻을 수 있다. (예: 원 모양 경계)

<br>

#### <u>Cost function for logistic regression</u>

![img](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png)

위의 두 식을 합쳐서 간단하게 만들면

![img](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[16].png)



위 식은 maximum likelihood estimation원칙을 사용할 수 있고 볼록함수이다.

<br>

##### How to minimize the logistic regression cost function

Gradient descent이기 때문에 모든 θ<sub>j</sub>가 동시에 업데이트 되어야한다.

for문을 사용하는것도 좋지만 벡터를 이용하는 것이 더 좋다.

<br>

#### <u>Advanced optimization</u>

- 장점

  알파를 자동으로 선택해준다.

  대부분의 경우에서 Gradient descent보다 빠르다.

  복잡한 코드를 이해하지 않고도 성공적으로 수행을 완료할 수 있다.

- 단점

  디버깅하기 어렵다.

  다른 라이브러리를 사용하면 수행을 완료하는데 차질이 생긴다.

<br>

#### <u>Multiclass classification problems</u>

다중 클래스를 분류할 때 1대 다(One vs. All) 분류를 사용한다.

x라는 새로운 데이터가 추가되었을 때, i class의 모든 h함수에 대해서 예측값을 구한다.

값이 가장 큰 class가 x가 속하게 되는 class가 된다.